{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae0a44a0",
   "metadata": {},
   "source": [
    "# Práctica NLP\n",
    "Hecha por Rubén Cerezo Cuesta\n",
    "En esta práctica, vamos a hacer dos modelos de NLP a partir de un dataset de Amazon formado por reseñas de videojuegos. Con esto, esperamos conseguir un análisis de sentimiento. Tras entrenar estos modelos, podremos conseguir una herramienta que catalogue reviews en función de cómo de positivas son. \n",
    "Este trabajo está dividido en 4 fases:\n",
    "- Exploración de datos\n",
    "- **Preprocesamiento de datos**\n",
    "- división Train/Test y entrenamiento\n",
    "- Métricas y conclusiones\n",
    "En este caso, el corpus elegido, de Amazon, incluye reviews de videojuegos, simplemente por ser un tema que conozco y que he pensado que podría resultar fácil a la hora de reconocer el producto con el que trabajo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13ae000",
   "metadata": {},
   "source": [
    "## Preprocesado\n",
    "En este notebook, vamos a realizar los siguientes pasos : \n",
    "- Cargamos el archivo .csv donde se encuentra el corpus\n",
    "-El alumno preparará una etapa de preprocesado de reviews que permita adecuar\n",
    "el formato de las mismas a uno más adecuado. Será la etapa previa al entrenamiento del\n",
    "modelo de sentimiento.\n",
    "Todo el preprocesado deberá incluirse en una función de Python que contenga\n",
    "todo el procesado de texto. Esta función puede (es recomendable) contener otras funciones\n",
    "que realicen tareas más concretas (eliminar stopwords, eliminar signos de puntuación, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18502edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement unicodedata (from versions: none)\n",
      "ERROR: No matching distribution found for unicodedata\n"
     ]
    }
   ],
   "source": [
    "!pip install unicodedata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90e2b1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3DLWSSO2LVC1E</td>\n",
       "      <td>B000FDOTIQ</td>\n",
       "      <td>Kora</td>\n",
       "      <td>[4, 6]</td>\n",
       "      <td>Final Fantasy VII for the ps1 was (and still i...</td>\n",
       "      <td>2</td>\n",
       "      <td>More like a movie than a game.</td>\n",
       "      <td>1164844800</td>\n",
       "      <td>11 30, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AJIDIVBILJKO0</td>\n",
       "      <td>B002DY9KHU</td>\n",
       "      <td>MekoRush</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Yeah it's ok. it was easy to get use to the co...</td>\n",
       "      <td>3</td>\n",
       "      <td>Sneakly reviewing this game, it's ok</td>\n",
       "      <td>1334534400</td>\n",
       "      <td>04 16, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3PZ4AXTY9J1DZ</td>\n",
       "      <td>B000R39GPA</td>\n",
       "      <td>Jason Ralsky</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>Star Wars: The Force Unleashed (SW:TFU) at lau...</td>\n",
       "      <td>3</td>\n",
       "      <td>Misses the mark of past Jedi games just barely</td>\n",
       "      <td>1287964800</td>\n",
       "      <td>10 25, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AW3BDUZUFZMFX</td>\n",
       "      <td>B0000A92KZ</td>\n",
       "      <td>Joshua T. Garcia</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>This review may contain minor spoilers. It was...</td>\n",
       "      <td>2</td>\n",
       "      <td>The Fall of Max Payne</td>\n",
       "      <td>1318118400</td>\n",
       "      <td>10 9, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1GBZD75UNMD2B</td>\n",
       "      <td>B001TOQ8R0</td>\n",
       "      <td>Adgear \"Derebu\"</td>\n",
       "      <td>[8, 9]</td>\n",
       "      <td>I'm having the same problems as everyone else ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Don't buy this game!!</td>\n",
       "      <td>1269388800</td>\n",
       "      <td>03 24, 2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin      reviewerName helpful  \\\n",
       "0  A3DLWSSO2LVC1E  B000FDOTIQ              Kora  [4, 6]   \n",
       "1   AJIDIVBILJKO0  B002DY9KHU          MekoRush  [0, 0]   \n",
       "2  A3PZ4AXTY9J1DZ  B000R39GPA      Jason Ralsky  [2, 2]   \n",
       "3   AW3BDUZUFZMFX  B0000A92KZ  Joshua T. Garcia  [1, 2]   \n",
       "4  A1GBZD75UNMD2B  B001TOQ8R0   Adgear \"Derebu\"  [8, 9]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  Final Fantasy VII for the ps1 was (and still i...        2   \n",
       "1  Yeah it's ok. it was easy to get use to the co...        3   \n",
       "2  Star Wars: The Force Unleashed (SW:TFU) at lau...        3   \n",
       "3  This review may contain minor spoilers. It was...        2   \n",
       "4  I'm having the same problems as everyone else ...        1   \n",
       "\n",
       "                                          summary  unixReviewTime   reviewTime  \n",
       "0                  More like a movie than a game.      1164844800  11 30, 2006  \n",
       "1            Sneakly reviewing this game, it's ok      1334534400  04 16, 2012  \n",
       "2  Misses the mark of past Jedi games just barely      1287964800  10 25, 2010  \n",
       "3                           The Fall of Max Payne      1318118400   10 9, 2011  \n",
       "4                           Don't buy this game!!      1269388800  03 24, 2010  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cargamos el archivo .csv \n",
    "import pandas as pd\n",
    "\n",
    "path = r'C:\\Users\\rammu\\Documents\\projects\\NLP_04\\práctica\\reviews_Video_Games_5_balanced.csv'\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9162810",
   "metadata": {},
   "source": [
    "Como vemos, el dataset vuelve a estar con todas las columnas, ya que el notebook anterior sólo lo utilizamos para analizar, pero el preprocesado real va a ocurrir en este notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b039c00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Final Fantasy VII for the ps1 was (and still i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yeah it's ok. it was easy to get use to the co...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Star Wars: The Force Unleashed (SW:TFU) at lau...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This review may contain minor spoilers. It was...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm having the same problems as everyone else ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall\n",
       "0  Final Fantasy VII for the ps1 was (and still i...        2\n",
       "1  Yeah it's ok. it was easy to get use to the co...        3\n",
       "2  Star Wars: The Force Unleashed (SW:TFU) at lau...        3\n",
       "3  This review may contain minor spoilers. It was...        2\n",
       "4  I'm having the same problems as everyone else ...        1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Eliminamos columnas innecesarias\n",
    "df_balanced = df.drop(columns=['reviewerID', 'asin', 'reviewerName', 'helpful', 'unixReviewTime', 'reviewTime', 'summary'])\n",
    "df_balanced.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c0ca0f",
   "metadata": {},
   "source": [
    "Como dijimos en el notebook anterior, parte del preprocesado de los datos incluiría eliminar de nuestro corpus aquellos nombres que puedan pertenecer a franquicias. Para ello, lo primero que vamos a hacer es visualizar todo aquello que Spacy reconoce como entidades y cuáles son sus categorías. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96dfc2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ORG ===\n",
      "  - Final Fantasy VII\n",
      "  - RPG\n",
      "  - WANT\n",
      "  - Final Fantasy VII\n",
      "  - Advent Children\n",
      "  - DBZ\n",
      "  - SW\n",
      "  - TFU\n",
      "  - Starkiller\n",
      "  - holocron\n",
      "\n",
      "=== CARDINAL ===\n",
      "  - 3\n",
      "  - 1\n",
      "  - 2\n",
      "  - 2\n",
      "  - 3\n",
      "  - 1\n",
      "  - 2\n",
      "  - 5\n",
      "  - 4\n",
      "  - 4X\n",
      "\n",
      "=== TIME ===\n",
      "  - every two minutes or so\n",
      "  - about 6 hours\n",
      "  - an hour\n",
      "  - minutes\n",
      "  - 15 hours\n",
      "  - late night\n",
      "  - late at night\n",
      "  - only several hours\n",
      "  - only a few hours\n",
      "  - this evening\n",
      "\n",
      "=== DATE ===\n",
      "  - the year\n",
      "  - the years\n",
      "  - 2011\n",
      "  - a few weeks\n",
      "  - 30fps\n",
      "  - 1080p\n",
      "  - Tomorrow\n",
      "  - 10 years\n",
      "  - 194223\n",
      "  - 194224\n",
      "\n",
      "=== MONEY ===\n",
      "  - 20(what\n",
      "  - 20\n",
      "  - 30\n",
      "  - 9.99\n",
      "  - another $50\n",
      "  - 60\n",
      "  - another $50\n",
      "  - 90\n",
      "  - 34;Free\n",
      "  - 60\n",
      "\n",
      "=== PERSON ===\n",
      "  - Jedi Academy\n",
      "  - Lucas Arts\n",
      "  - 720p\n",
      "  - Max Payne\n",
      "  - Remedy\n",
      "  - Max Payne\n",
      "  - Remedy\n",
      "  - Max\n",
      "  - Max Payne\n",
      "  - Max Payne\n",
      "\n",
      "=== ORDINAL ===\n",
      "  - first\n",
      "  - second\n",
      "  - third\n",
      "  - first\n",
      "  - first\n",
      "  - first\n",
      "  - third\n",
      "  - first\n",
      "  - first\n",
      "  - first\n",
      "\n",
      "=== EVENT ===\n",
      "  - the Dark Side / Light Side\n",
      "  - World v World v World\n",
      "  - WWII\n",
      "  - Mediocrity Assurance Committees\n",
      "  - the Total War series\n",
      "  - the Total War\n",
      "  - The Worst Original\n",
      "  - E.T. Games\n",
      "  - WWII\n",
      "  - WWII\n",
      "\n",
      "=== QUANTITY ===\n",
      "  - a ton\n",
      "  - 10 feet\n",
      "  - 200 + yards\n",
      "  - about 8 dishes\n",
      "  - over 16 square miles\n",
      "  - a mile\n",
      "  - a ton\n",
      "  - two meters\n",
      "  - a ton\n",
      "  - 5 ft\n",
      "\n",
      "=== PERCENT ===\n",
      "  - 78%\n",
      "  - 88%\n",
      "  - 100%\n",
      "  - almost 100%\n",
      "  - 89%\n",
      "  - 90%\n",
      "  - 3 and 90%\n",
      "  - 90 percent\n",
      "  - 100%\n",
      "  - 100%\n",
      "\n",
      "=== GPE ===\n",
      "  - Rockstar\n",
      "  - colonies\n",
      "  - Montoya\n",
      "  - Vengeance\n",
      "  - shooter15\n",
      "  - Turbo\n",
      "  - frustrating30\n",
      "  - gallery32\n",
      "  - Fahrenheit\n",
      "  - Beyond\n",
      "\n",
      "=== PRODUCT ===\n",
      "  - Xbox\n",
      "  - 900p\n",
      "  - Classic\n",
      "  - controls9\n",
      "  - up14\n",
      "  - Classic\n",
      "  - 109 II\n",
      "  - area37\n",
      "  - Classic - 2D\n",
      "  - Shadow\n",
      "\n",
      "=== LOC ===\n",
      "  - NBA2K\n",
      "  - buggies12\n",
      "  - Heavy Rain\n",
      "  - Heavy Rain\n",
      "  - Keyblades\n",
      "  - Harvest Moon\n",
      "  - Aparoids\n",
      "  - Borg\n",
      "  - the Super Nintendo\n",
      "  - Earth\n",
      "\n",
      "=== WORK_OF_ART ===\n",
      "  - Tomb Raider\n",
      "  - Batman\n",
      "  - Break it Down\" Blog\n",
      "  - PvP\n",
      "  - gallery7\n",
      "  - LoL\n",
      "  - elsewhere2\n",
      "  - Farmville\n",
      "  - PGA Tour 09\n",
      "  - Amateurs\n",
      "\n",
      "=== FAC ===\n",
      "  - Sin Tzu Batman\n",
      "  - gallery43\n",
      "  - Arwing\n",
      "  - Die Hard\n",
      "  - Husband\n",
      "  - Dragonborn\n",
      "  - Port Royale 2\n",
      "  - Port Royale 2\n",
      "  - Port Royale 2\n",
      "  - Elm Street\n",
      "\n",
      "=== LAW ===\n",
      "  - World v World v World\n",
      "  - the Pata Pata Pata PON\n",
      "  - DoA\n",
      "  - XBox One\n",
      "  - Episode 2\n",
      "  - Act 3\n",
      "  - Act 3\n",
      "  - SteelSeries 4HD\n",
      "  - Notice I\n",
      "  - the Mad Catz 5\n",
      "\n",
      "=== LANGUAGE ===\n",
      "  - above5\n",
      "  - Punch\n",
      "  - Latin\n",
      "  - english\n",
      "  - english\n",
      "  - English\n",
      "  - Spanish\n",
      "  - Spanish\n",
      "  - English\n",
      "  - English\n",
      "\n",
      "=== NORP ===\n",
      "  - Europeans\n",
      "  - Modern\n",
      "  - Victorian\n",
      "  - Austrian\n",
      "  - German\n",
      "  - French\n",
      "  - Victorian\n",
      "  - Survival\n",
      "  - russian\n",
      "  - illuminati\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "#visualizar categorías de entidades en el NER DE spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\"])\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "entity_examples = defaultdict(list)\n",
    "\n",
    "for doc in nlp.pipe(df_balanced[\"reviewText\"].astype(str), batch_size=50):\n",
    "    for ent in doc.ents:\n",
    "        if len(entity_examples[ent.label_]) < 10:   # muestra hasta 10 ejemplos por categoría\n",
    "            entity_examples[ent.label_].append(ent.text)\n",
    "\n",
    "# Mostrar resultados\n",
    "for label, examples in entity_examples.items():\n",
    "    print(f\"\\n=== {label} ===\")\n",
    "    for e in examples:\n",
    "        print(\"  -\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd8c1c2",
   "metadata": {},
   "source": [
    "### Qué hacer con las entidades y franquicias: \n",
    "Visto esto, eliminaremos las siguientes categorías:\n",
    "1. ORG\n",
    "2. PERSON\n",
    "3. GPE\n",
    "4. PRODUCT\n",
    "5. LOC\n",
    "6. WORK_OF_ART\n",
    "7. FAC\n",
    "8. LAW\n",
    "\n",
    "Porque claramente, muestran entidades que no aportan al nivel de sentimiento, sino que se asociarían con el producto del que hablamos (por ejemplo, es claro que mencionen Star Wars en una review de un videojuego de esta franquicia, y también LucasArts, la compañía que lo produce)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "669dfa3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviewText overall 0 Final Fantasy VII for the ps1 was (and still i... 2 1 Yeah it's ok. it was easy to get use to the co... 3 2 Star Wars: The Force Unleashed (:) at lau... 3 3 This review may contain minor spoilers. It was... 2 4 I'm having the same problems as everyone else ... 1 ... ... ... 4995 Besides better graphics and effects the overal... 5 4996 i picked this up in a bargain bin at a local v... 1 4997 I played the first Sniper Elite and my beef wa... 4 4998 SimCity 4 is the latest in the long-survived S... 4 4999 THESE GAMES ARE STUPID, MAKE NO SENSE AT ALL. ... 1 [5000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def remove_entities(text):\n",
    "    \"\"\"\n",
    "    Recibe un string, aplica NER con spaCy y elimina las entidades\n",
    "    pertenecientes a REMOVE_LABELS. Devuelve un string limpio.\n",
    "    \"\"\"\n",
    "    import spacy\n",
    "\n",
    "    # Cargar spaCy solo una vez sería mejor, pero aquí respetamos tu estilo\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\"])\n",
    "\n",
    "    REMOVE_LABELS = {\n",
    "        \"ORG\", \"PERSON\", \"GPE\", \"PRODUCT\",\n",
    "        \"LOC\", \"WORK_OF_ART\", \"FAC\", \"LAW\"\n",
    "    }\n",
    "\n",
    "    # Convertir a string (por seguridad)\n",
    "    text = str(text)\n",
    "\n",
    "    # Procesamos el texto\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Identificar spans a eliminar\n",
    "    spans_to_remove = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in REMOVE_LABELS:\n",
    "            spans_to_remove.append((ent.start_char, ent.end_char))\n",
    "\n",
    "    # Si no hay entidades → devolvemos el texto normalizado\n",
    "    if not spans_to_remove:\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    # Construir el texto sin las entidades\n",
    "    cleaned_parts = []\n",
    "    last_end = 0\n",
    "\n",
    "    for start, end in spans_to_remove:\n",
    "        cleaned_parts.append(text[last_end:start])\n",
    "        last_end = end\n",
    "\n",
    "    cleaned_parts.append(text[last_end:])\n",
    "    cleaned_text = \"\".join(cleaned_parts)\n",
    "\n",
    "    # Normalizar espacios antes de devolver\n",
    "    return \" \".join(cleaned_text.split())\n",
    "print (remove_entities(df_balanced))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59dfef9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>final fantasy vii ps1 consider good rpgs creat...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yeah ok easy use control ol story you ll play ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>star war force unleash swtfu launch probably h...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>review contain minor spoiler write specificall...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I m have problem get disconnected huge waste m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall\n",
       "0  final fantasy vii ps1 consider good rpgs creat...        2\n",
       "1  yeah ok easy use control ol story you ll play ...        3\n",
       "2  star war force unleash swtfu launch probably h...        3\n",
       "3  review contain minor spoiler write specificall...        2\n",
       "4  I m have problem get disconnected huge waste m...        1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from funciones_preprocesamiento import preprocess_text, remove_stopwords, lemmatize_text\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "stopwords = set(STOP_WORDS)\n",
    "\n",
    "# Preprocesamos, como en el anterior notebook, las review, quitando puntuación, pasando a minúsculas \n",
    "df_balanced= preprocess_text(df_balanced)   \n",
    "# Quitamos stopwords\n",
    "\n",
    "df_balanced[\"reviewText\"] = df_balanced[\"reviewText\"].apply(lambda text: remove_stopwords(text, stopwords))\n",
    "df_balanced[\"reviewText\"] = df_balanced[\"reviewText\"].apply(lemmatize_text)\n",
    "df_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0387b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[final, fantasy, vii, ps1, consider, good, rpg...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[yeah, ok, easy, use, control, ol, story, you,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[star, war, force, unleash, swtfu, launch, pro...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[review, contain, minor, spoiler, write, speci...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[I, m, have, problem, get, disconnected, huge,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall\n",
       "0  [final, fantasy, vii, ps1, consider, good, rpg...        2\n",
       "1  [yeah, ok, easy, use, control, ol, story, you,...        3\n",
       "2  [star, war, force, unleash, swtfu, launch, pro...        3\n",
       "3  [review, contain, minor, spoiler, write, speci...        2\n",
       "4  [I, m, have, problem, get, disconnected, huge,...        1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tras todo el preprocesado, hacemos una tokenización final:\n",
    "def tokenize(text):\n",
    "    return text.split()\n",
    "# Aplicamos la tokenización\n",
    "df_balanced[\"reviewText\"] = df_balanced[\"reviewText\"].apply(tokenize)\n",
    "df_balanced.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "512cf68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original review:\n",
      " Final Fantasy VII for the ps1 was (and still is) considered one of the best RPG's ever created. The same cannot be said for the spin off of a side quest character that tries too hard to be hard core and ends up being mistaken for a Devil May Cry clone.The good news:-You can customize your weapons to cause maximum damage.-It's kind of neat to see final fantasy VII characters in 3-D with voices.The bad news:-This game is horribly paced. You can't get into the game play because there's a cut scene every two minutes or so. Most of them have nothing to do with where you are fighting so they seem terribly misplaced and you just don't really care enough about the characters to WANT to watch them. This game is way too concerned about being an animated movie rather than an actual game.-The aiming system is shot and you cannot lock onto enemies the way you should be able to. If this had been fixed, this could have at least been an average game.-The same goes for the camera, you never face the direction you want to face and that immediately gives this game the score that I've chosen for it.I love Final Fantasy VII for the ps1. I even liked Advent Children a little bit. But this is criminal for anyone who likes the franchise.\n",
      "\n",
      "Preprocessed review:\n",
      " ['final', 'fantasy', 'vii', 'ps1', 'consider', 'good', 'rpgs', 'create', 'say', 'spin', 'quest', 'character', 'try', 'hard', 'hard', 'core', 'end', 'mistaken', 'devil', 'cry', 'clonethe', 'good', 'newsyou', 'customize', 'weapon', 'cause', 'maximum', 'damageit', 'kind', 'neat', 'final', 'fantasy', 'vii', 'character', '3d', 'voicesthe', 'bad', 'newsthis', 'game', 'horribly', 'pace', 'can', 'not', 'game', 'play', 'there', 's', 'cut', 'scene', 'minute', 'fight', 'terribly', 'misplace', 'do', 'not', 'care', 'character', 'want', 'watch', 'game', 'way', 'concern', 'animated', 'movie', 'actual', 'gamethe', 'aim', 'system', 'shoot', 'lock', 'enemy', 'way', 'able', 'fix', 'average', 'gamethe', 'go', 'camera', 'face', 'direction', 'want', 'face', 'immediately', 'give', 'game', 'score', 'I', 've', 'choose', 'iti', 'love', 'final', 'fantasy', 'vii', 'ps1', 'like', 'advent', 'child', 'little', 'bit', 'criminal', 'like', 'franchise']\n"
     ]
    }
   ],
   "source": [
    "import unicodedata,re\n",
    "#mostramos una review original y su versión preprocesada\n",
    "t = df['reviewText'].iloc[0]\n",
    "t_processed = df_balanced['reviewText'].iloc[0]\n",
    "print(\"Original review:\\n\", t)\n",
    "print(\"\\nPreprocessed review:\\n\", t_processed)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3362425b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Por último, guardamos el dataframe preprocesado en un nuevo archivo .csv\n",
    "df_balanced.to_csv('reviews_Video_Games_5_balanced_preprocessed.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fb2ae0",
   "metadata": {},
   "source": [
    "# Creación de una función que englobe todo este proceso: \n",
    "\n",
    "Para finalizar, y después de haber ido haciendo todo el proceso poco a poco, vamos a crear una función que haga todos los pasos anteriores para así evitar tener que revisar código en caso de que, en futuros entrenamientos haya que volver a entrenar el modelo con nuevas entradas en el corpus: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c84db92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype reviewText: object\n",
      "nulos reviewText: 0\n",
      "Ejemplos nulos / None:\n",
      "Empty DataFrame\n",
      "Columns: [reviewText, overall]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(\"dtype reviewText:\", df_balanced['reviewText'].dtype)\n",
    "print(\"nulos reviewText:\", df_balanced['reviewText'].isna().sum())\n",
    "print(\"Ejemplos nulos / None:\")\n",
    "print(df_balanced[df_balanced['reviewText'].isna()].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a7d6c9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     34\u001b[39m     df_balanced.to_csv(output_path, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df_balanced \n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[43mpreprocess_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m df_balanced.head\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mpreprocess_complete\u001b[39m\u001b[34m(input_path, output_path)\u001b[39m\n\u001b[32m     18\u001b[39m     df_balanced = df.drop(columns=[\u001b[33m'\u001b[39m\u001b[33mreviewerID\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33masin\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mreviewerName\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhelpful\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33munixReviewTime\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mreviewTime\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msummary\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     19\u001b[39m     \u001b[38;5;66;03m#Aplicamos las funciones que hemos creado para este preprocesamiento:\u001b[39;00m\n\u001b[32m     20\u001b[39m     \u001b[38;5;66;03m#Remove entities para eliminar títulos de videojuegos\u001b[39;00m\n\u001b[32m     21\u001b[39m     \u001b[38;5;66;03m#preprocess_text para eliminar mayúsculas y puntuación\u001b[39;00m\n\u001b[32m     22\u001b[39m     \u001b[38;5;66;03m# remove_stopwords para eliminar palabras con poca carga semántica.\u001b[39;00m\n\u001b[32m     23\u001b[39m     \u001b[38;5;66;03m#lemmatize_text para mantener sólo las raíces de las palabras\u001b[39;00m\n\u001b[32m     24\u001b[39m     df_balanced[\u001b[33m\"\u001b[39m\u001b[33mreviewText\u001b[39m\u001b[33m\"\u001b[39m] = (\n\u001b[32m     25\u001b[39m     \u001b[43mdf_balanced\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreviewText\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[43m.\u001b[49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremove_entities\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[43m        \u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m         .apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: remove_stopwords(t, stopwords))\n\u001b[32m     31\u001b[39m         .apply(lemmatize_text)\n\u001b[32m     32\u001b[39m )\n\u001b[32m     33\u001b[39m     \u001b[38;5;66;03m#Por último, guardamos nuestro corpus ya preprocesado en el \"output_path definido\" \u001b[39;00m\n\u001b[32m     34\u001b[39m     df_balanced.to_csv(output_path, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rammu\\Documents\\projects\\NLP_04\\Lib\\site-packages\\pandas\\core\\series.py:4943\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4808\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4809\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4810\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4815\u001b[39m     **kwargs,\n\u001b[32m   4816\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4817\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4818\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4819\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4934\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4935\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4936\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4937\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4938\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4939\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4940\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4941\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4942\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4943\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rammu\\Documents\\projects\\NLP_04\\Lib\\site-packages\\pandas\\core\\apply.py:1422\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1421\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rammu\\Documents\\projects\\NLP_04\\Lib\\site-packages\\pandas\\core\\apply.py:1502\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1496\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1499\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1500\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1501\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1502\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1507\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1508\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rammu\\Documents\\projects\\NLP_04\\Lib\\site-packages\\pandas\\core\\base.py:925\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    923\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rammu\\Documents\\projects\\NLP_04\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2999\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rammu\\Documents\\projects\\NLP_04\\práctica\\funciones_preprocesamiento.py:47\u001b[39m, in \u001b[36mpreprocess_text\u001b[39m\u001b[34m(dataset)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpreprocess_text\u001b[39m (dataset):\n\u001b[32m     40\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[33;03m    Esta función realiza un preprocesamiento básico del texto en la columna 'reviewText' de un dataframe de pandas.\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[33;03m    Convierte el texto a minúsculas y elimina los caracteres que no son letras ni números. \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     45\u001b[39m \u001b[33;03m    return: El dataframe con la columna 'reviewText' preprocesada.\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     dataset[\u001b[33m'\u001b[39m\u001b[33mreviewText\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mreviewText\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: re.sub(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m[^a-zA-Z0-9\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms]\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, x.lower()))\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "\u001b[31mTypeError\u001b[39m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from funciones_preprocesamiento import  preprocess_text, remove_stopwords, lemmatize_text\n",
    "input_path = r'C:\\Users\\rammu\\Documents\\projects\\NLP_04\\práctica\\reviews_Video_Games_5_balanced.csv'\n",
    "output_path = r'C:\\Users\\rammu\\Documents\\projects\\NLP_04\\práctica\\reviews_Video_Games_5_balanced_preprocessed.csv'\n",
    "def preprocess_complete (input_path = input_path , output_path= output_path):\n",
    "    \"\"\"\n",
    "    Esta función hace el preprocesamiento completo del texto, utilizando las funciones ya definidas antes. Como parámetros, usa el path donde el .csv está guardado, y el path donde \n",
    "    queremos guardar nuestro dataset ya preprocesado \n",
    "    \n",
    "    :param input_path: como input_path mantenemos la ruta donde está guardado el archivo\n",
    "    :param output_path: Como output_path ponemos la ruta donde queremos guardar el archivo, normalmente la carpeta raíz del proyecto, para poder mantener coherencia con el siguiente notebook\n",
    "\n",
    "    \"\"\"\n",
    "    #Cargamos el dataset\n",
    "    df = pd.read_csv(input_path)\n",
    "    #Eliminamos las columnas innecesarias\n",
    "    df_balanced = df.drop(columns=['reviewerID', 'asin', 'reviewerName', 'helpful', 'unixReviewTime', 'reviewTime', 'summary'])\n",
    "    #Aplicamos las funciones que hemos creado para este preprocesamiento:\n",
    "    #Remove entities para eliminar títulos de videojuegos\n",
    "    #preprocess_text para eliminar mayúsculas y puntuación\n",
    "    # remove_stopwords para eliminar palabras con poca carga semántica.\n",
    "    #lemmatize_text para mantener sólo las raíces de las palabras\n",
    "    df_balanced[\"reviewText\"] = (\n",
    "    df_balanced[\"reviewText\"]\n",
    "        .fillna(\"\")\n",
    "        .astype(str)\n",
    "        .apply(remove_entities)\n",
    "        .apply(preprocess_text)\n",
    "        .apply(lambda t: remove_stopwords(t, stopwords))\n",
    "        .apply(lemmatize_text)\n",
    ")\n",
    "    #Por último, guardamos nuestro corpus ya preprocesado en el \"output_path definido\" \n",
    "    df_balanced.to_csv(output_path, index=False)\n",
    "    \n",
    "    return df_balanced \n",
    "\n",
    "preprocess_complete()\n",
    "df_balanced.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7135ff6f",
   "metadata": {},
   "source": [
    "Creamos un segundo csv en el que cambiamos las reseñas a valores 0-1 (negativo y positivo) para simplificar el modelo y conseguir una mayor accuracy. \n",
    "Sin embargo, he hecho 2 notebooks distintos que usaré para comparar los resultados entre modelos entrenados con distintos corpus. \n",
    "Para esto, vamos a cambiar las reseñas puntuadas con 1 y 2 a un valor 0 (negativo) y las reseñas puntuadas con 4 y 5 a un valor 1 (positivo). \n",
    "Tras hacer una pequeña búsqueda en Google, he decidido desechar las reseñas evaluadas en 3 dado que, al ser neutras, podrian aportar ruido y reducir la precisión del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249c3c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall\n",
       "0    2000\n",
       "1    2000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path= r'C:\\Users\\rammu\\Documents\\projects\\NLP_04\\práctica\\reviews_Video_Games_5_balanced_preprocessed.csv'\n",
    "def change_overall(corpus, path):\n",
    "    \"\"\"\n",
    "    Esta función transforma puntuaciones 1-5 en sentimiento binario:\n",
    "    - 1 y 2 => 0 (negativo)\n",
    "    - 4 y 5 => 1 (positivo)\n",
    "    Elimina las puntuaciones neutras (3).\n",
    "\n",
    "    Recibe la ruta del archivo .csv y un dataframe (no usado) y devuelve\n",
    "    el dataframe modificado. Además, guarda un nuevo .csv.\n",
    "    \"\"\"\n",
    "\n",
    "    # Cargar dataset desde la ruta\n",
    "    corpus = pd.read_csv(path)\n",
    "\n",
    "    # Eliminar reseñas con puntuación = 3\n",
    "    corpus = corpus[corpus['overall'] != 3].copy()\n",
    "\n",
    "    # Aplicar mapeo a 0 (negativo) o 1 (positivo)\n",
    "    corpus['overall'] = corpus['overall'].apply(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "    # Guardar nuevo archivo\n",
    "    output_path = 'reviews_Video_Games_5_balanced_preprocessed_0-1.csv'\n",
    "    corpus.to_csv(output_path, index=False)\n",
    "\n",
    "    return corpus\n",
    "#aplicamos la función\n",
    "df_final= change_overall(df_balanced, path)\n",
    "#comprobamos el resultado\n",
    "df_final = pd.read_csv('reviews_Video_Games_5_balanced_preprocessed_0-1.csv')\n",
    "df_final['overall'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_04",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
